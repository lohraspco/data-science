{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D,MaxPooling2D,UpSampling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_img = Input((64,64,3))\n",
    "x = Conv2D(64,(3,3),activation='relu',padding='same')(input_img)\n",
    "x = MaxPooling2D((3,3),padding='same')(x)\n",
    "x = Conv2D(32,(3,3),activation='relu',padding='same')(x)\n",
    "x = MaxPooling2D((3,3),padding='same')(x)\n",
    "encoded = Conv2D(8,(3,3),activation='relu')(x)\n",
    "encoder = Model(input_img,encoded)\n",
    "#encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_input = Input( (6, 6, 8) )\n",
    "x = Conv2D(32,(3,3),activation='relu',padding='same')(middle_input)\n",
    "\n",
    "x = UpSampling2D((3,3))(x)\n",
    "x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n",
    "x = UpSampling2D((3,3))(x)\n",
    "decoded = Conv2D(3,(3,3),activation='sigmoid',padding='same')(x)\n",
    "decoder = Model(middle_input,decoded)\n",
    "\n",
    "autoencoder = Model(input_img,decoder(encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 6, 6, 8)]         0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 6, 6, 32)          2336      \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 18, 18, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 18, 18, 64)        18496     \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 54, 54, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 54, 54, 3)         1731      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,563\n",
      "Trainable params: 22,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 22, 22, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 22, 22, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 8, 8, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 6, 6, 8)           2312      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,568\n",
      "Trainable params: 22,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [32,54,54,3] vs. [32,64,64,3]\n\t [[node gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs\n (defined at /home/lohrasp/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:464)\n]] [Op:__inference_train_function_1782]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs:\nIn[0] gradient_tape/binary_crossentropy/logistic_loss/mul/Shape:\t\nIn[1] gradient_tape/binary_crossentropy/logistic_loss/mul/Shape_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"/home/lohrasp/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/pythonFiles/vscode_datascience_helpers/kernel_prewarm_starter.py\", line 31, in <module>\n>>>     runpy.run_module(module, run_name=\"__main__\", alter_sys=False)\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 210, in run_module\n>>>     return _run_code(code, {}, init_globals, run_name, mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 362, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 265, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2886, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2932, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3155, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3347, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3427, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-28-b6a5b1a946e3>\", line 4, in <module>\n>>>     history = autoencoder.fit(image_loader,epochs=1,verbose=1)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b6a5b1a946e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [32,54,54,3] vs. [32,64,64,3]\n\t [[node gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs\n (defined at /home/lohrasp/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:464)\n]] [Op:__inference_train_function_1782]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs:\nIn[0] gradient_tape/binary_crossentropy/logistic_loss/mul/Shape:\t\nIn[1] gradient_tape/binary_crossentropy/logistic_loss/mul/Shape_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"/home/lohrasp/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/pythonFiles/vscode_datascience_helpers/kernel_prewarm_starter.py\", line 31, in <module>\n>>>     runpy.run_module(module, run_name=\"__main__\", alter_sys=False)\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 210, in run_module\n>>>     return _run_code(code, {}, init_globals, run_name, mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 362, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 265, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2886, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2932, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3155, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3347, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3427, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-28-b6a5b1a946e3>\", line 4, in <module>\n>>>     history = autoencoder.fit(image_loader,epochs=1,verbose=1)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"/home/lohrasp/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> "
     ]
    }
   ],
   "source": [
    "gener = ImageDataGenerator(rescale=1./255)\n",
    "image_loader = gener.flow_from_directory(\"images/\",target_size=(64,64),class_mode='input')\n",
    "autoencoder.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "history = autoencoder.fit(image_loader,epochs=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 22, 22, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 22, 22, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 8, 8, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 6, 6, 8)           2312      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,568\n",
      "Trainable params: 22,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function flow_from_directory in module keras.preprocessing.image:\n",
      "\n",
      "flow_from_directory(self, directory, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', follow_links=False, subset=None, interpolation='nearest')\n",
      "    Takes the path to a directory & generates batches of augmented data.\n",
      "    \n",
      "    Args:\n",
      "        directory: string, path to the target directory. It should contain one\n",
      "          subdirectory per class. Any PNG, JPG, BMP, PPM or TIF images inside\n",
      "          each of the subdirectories directory tree will be included in the\n",
      "          generator. See [this script](\n",
      "            https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n",
      "              for more details.\n",
      "        target_size: Tuple of integers `(height, width)`, defaults to `(256,\n",
      "          256)`. The dimensions to which all images found will be resized.\n",
      "        color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". Whether\n",
      "          the images will be converted to have 1, 3, or 4 channels.\n",
      "        classes: Optional list of class subdirectories\n",
      "            (e.g. `['dogs', 'cats']`). Default: None. If not provided, the list\n",
      "              of classes will be automatically inferred from the subdirectory\n",
      "              names/structure under `directory`, where each subdirectory will be\n",
      "              treated as a different class (and the order of the classes, which\n",
      "              will map to the label indices, will be alphanumeric). The\n",
      "              dictionary containing the mapping from class names to class\n",
      "              indices can be obtained via the attribute `class_indices`.\n",
      "        class_mode: One of \"categorical\", \"binary\", \"sparse\",\n",
      "            \"input\", or None. Default: \"categorical\".\n",
      "            Determines the type of label arrays that are returned:\n",
      "            - \"categorical\" will be 2D one-hot encoded labels,\n",
      "            - \"binary\" will be 1D binary labels,\n",
      "            - \"sparse\" will be 1D integer labels,\n",
      "            - \"input\"  will be images identical to input images (mainly used to\n",
      "              work with autoencoders).\n",
      "            - If None, no labels are returned (the generator will only yield\n",
      "              batches of image data, which is useful to use with\n",
      "              `model.predict()`).\n",
      "            Please note that in case of class_mode None, the data still needs to\n",
      "            reside in a subdirectory of `directory` for it to work correctly.\n",
      "        batch_size: Size of the batches of data (default: 32).\n",
      "        shuffle: Whether to shuffle the data (default: True) If set to False,\n",
      "          sorts the data in alphanumeric order.\n",
      "        seed: Optional random seed for shuffling and transformations.\n",
      "        save_to_dir: None or str (default: None). This allows you to optionally\n",
      "          specify a directory to which to save the augmented pictures being\n",
      "          generated (useful for visualizing what you are doing).\n",
      "        save_prefix: Str. Prefix to use for filenames of saved pictures (only\n",
      "          relevant if `save_to_dir` is set).\n",
      "        save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n",
      "            \"tif\", \"jpg\"\n",
      "            (only relevant if `save_to_dir` is set). Default: \"png\".\n",
      "        follow_links: Whether to follow symlinks inside\n",
      "            class subdirectories (default: False).\n",
      "        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
      "          `validation_split` is set in `ImageDataGenerator`.\n",
      "        interpolation: Interpolation method used to resample the image if the\n",
      "          target size is different from that of the loaded image. Supported\n",
      "          methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`. If PIL version\n",
      "          1.1.3 or newer is installed, `\"lanczos\"` is also supported. If PIL\n",
      "          version 3.4.0 or newer is installed, `\"box\"` and `\"hamming\"` are also\n",
      "          supported. By default, `\"nearest\"` is used.\n",
      "    \n",
      "    Returns:\n",
      "        A `DirectoryIterator` yielding tuples of `(x, y)`\n",
      "            where `x` is a numpy array containing a batch\n",
      "            of images with shape `(batch_size, *target_size, channels)`\n",
      "            and `y` is a numpy array of corresponding labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ImageDataGenerator.flow_from_directory)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
