{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5432,  # Change from 5433 to 5432\n",
    "    database=\"postgres\",\n",
    "    user=\"admin\",\n",
    "    password=\"lohraspco\"\n",
    ")\n",
    "engine = create_engine(f\"postgresql+psycopg2://admin:lohraspco@localhost:5432/postgres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionary of files and table definitions\n",
    "files_and_schemas = {\n",
    "    # \"tag.csv\": \"\"\"\n",
    "    #     CREATE TABLE IF NOT EXISTS saffron.tag (\n",
    "    #         userId INT,\n",
    "    #         movieId INT,\n",
    "    #         tag TEXT,\n",
    "    #         timestamp TIMESTAMP\n",
    "    #     );\n",
    "    # \"\"\",\n",
    "    # \"genome_scores.csv\": \"\"\"\n",
    "    #     CREATE TABLE IF NOT EXISTS saffron.genome_scores (\n",
    "    #         movieId INT,\n",
    "    #         tagId INT,\n",
    "    #         relevance FLOAT\n",
    "    #     );\n",
    "    # \"\"\",\n",
    "    \"rating.csv\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS saffron.rating (\n",
    "            userId INT,\n",
    "            movieId INT,\n",
    "            rating FLOAT,\n",
    "            timestamp TIMESTAMP\n",
    "        );\n",
    "    \"\"\",\n",
    "    \"movie.csv\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS saffron.movie (\n",
    "            movieId INT,\n",
    "            title TEXT,\n",
    "            genres TEXT\n",
    "        );\n",
    "    \"\"\",\n",
    "    \"link.csv\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS saffron.link (\n",
    "            movieId INT,\n",
    "            imdbId INT,\n",
    "            tmdbId INT \n",
    "        );\n",
    "    \"\"\",\n",
    "    \"genome_tags.csv\": \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS saffron.genome_tags (\n",
    "            tagId INT,\n",
    "            tag TEXT\n",
    "        );\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Step 1: Create a connection to PostgreSQL\n",
    "# Step 2: Create tables and ingest data\n",
    "def create_and_ingest(connection, engine, file_name, schema):\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Create table\n",
    "        cursor.execute(schema)\n",
    "        connection.commit()\n",
    "\n",
    "        print(f\"Table for {file_name} created successfully.\")\n",
    "\n",
    "        # Load CSV into DataFrame\n",
    "        df = pd.read_csv(file_name)\n",
    "\n",
    "        # Insert data into the table\n",
    "        # for _, row in df.iterrows():\n",
    "        #     insert_query = f\"\"\"\n",
    "        #     INSERT INTO saffron.{file_name.split('.')[0]} ({\", \".join(df.columns)}) \n",
    "        #     VALUES ({\", \".join(['%s'] * len(row))});\n",
    "        #     \"\"\"\n",
    "        #     cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "        # connection.commit()\n",
    "        print(f\"Data from '{file_name}' inserted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "    finally:\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user=admin password=xxx dbname=postgres host=localhost port=5432'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.dsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for rating.csv created successfully.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file, schema \u001b[38;5;129;01min\u001b[39;00m files_and_schemas\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     create_and_ingest(conn, file, schema)\n",
      "Cell \u001b[1;32mIn[28], line 69\u001b[0m, in \u001b[0;36mcreate_and_ingest\u001b[1;34m(connection, file_name, schema)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     65\u001b[0m     insert_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124m    INSERT INTO saffron.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124m    VALUES (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(row))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m);\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 69\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(insert_query, \u001b[38;5;28mtuple\u001b[39m(row))\n\u001b[0;32m     71\u001b[0m connection\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m inserted successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mamma\\anaconda3\\Lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file, schema in files_and_schemas.items():\n",
    "    create_and_ingest(conn, file, schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"spy.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\n",
    "        host=\"192.168.0.108\",\n",
    "        database=\"postgres\",\n",
    "        user=\"postgres\",\n",
    "        password=\"reallyStrongPwd123\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://admin:lohraspco@localhost:5432/postgres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"symbol\"] = \"spy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(name='stocks', con=engine,if_exists='append', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    for index, row in df.iterrows():\n",
    "        insert_query = sql.SQL(\"\"\"\n",
    "            INSERT INTO stocks (symbol, date, stock_name, market, price, open, high, low, close, volume)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (symbol, date) DO UPDATE\n",
    "            SET stock_name = EXCLUDED.stock_name,\n",
    "                market = EXCLUDED.market,\n",
    "                price = EXCLUDED.price,\n",
    "                open = EXCLUDED.open,\n",
    "                high = EXCLUDED.high,\n",
    "                low = EXCLUDED.low,\n",
    "                close = EXCLUDED.close,\n",
    "                volume = EXCLUDED.volume;\n",
    "        \"\"\")\n",
    "        \n",
    "        # Execute the query for each row\n",
    "        cursor.execute(insert_query, (\n",
    "            row['symbol'], row['date'], row['stock_name'], row['market'],\n",
    "            row['price'], row['open'], row['high'], row['low'],\n",
    "            row['close'], row['volume']\n",
    "        ))\n",
    "\n",
    "    # Commit the transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"la_restaurants.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:2].to_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"INSERT INTO vendors(vendor_name) VALUES(%s)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACTIVITY DATE', 'OWNER ID', 'OWNER NAME', 'FACILITY ID',\n",
       "       'FACILITY NAME', 'RECORD ID', 'PROGRAM NAME', 'PROGRAM STATUS',\n",
       "       'PROGRAM ELEMENT (PE)', 'PE DESCRIPTION', 'FACILITY ADDRESS',\n",
       "       'FACILITY CITY', 'FACILITY STATE', 'FACILITY ZIP', 'SERVICE CODE',\n",
       "       'SERVICE DESCRIPTION', 'SCORE', 'SERIAL NUMBER', 'EMPLOYEE ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = StringIO(\"\"\"col_names\n",
    "serial_number:\n",
    "varchar\n",
    "activity_date:\n",
    "datetime\n",
    "facility_name:\n",
    "varchar\n",
    "score:\n",
    "int\n",
    "grade:\n",
    "varchar\n",
    "service_code:\n",
    "int\n",
    "service_description:\n",
    "varchar\n",
    "employee_id:\n",
    "varchar\n",
    "facility_address:\n",
    "varchar\n",
    "facility_city:\n",
    "varchar\n",
    "facility_id:\n",
    "varchar\n",
    "facility_state:\n",
    "varchar\n",
    "facility_zip:\n",
    "varchar\n",
    "owner_id:\n",
    "varchar\n",
    "owner_name:\n",
    "varchar\n",
    "pe_description:\n",
    "varchar\n",
    "program_element_pe:\n",
    "int\n",
    "program_name:\n",
    "varchar\n",
    "program_status:\n",
    "varchar\n",
    "record_id:\n",
    "varchar\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(data)\n",
    "df3  = df2[0::2].assign(start=df2[::2].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['serial_number:', 'activity_date:', 'facility_name:', 'score:',\n",
    "       'grade:', 'service_code:', 'service_description:', 'employee_id:',\n",
    "       'facility_address:', 'facility_city:', 'facility_id:',\n",
    "       'facility_state:', 'facility_zip:', 'owner_id:', 'owner_name:',\n",
    "       'pe_description:', 'program_element_pe:', 'program_name:',\n",
    "       'program_status:', 'record_id:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 'SERIAL NUMBER','ACTIVITY DATE','FACILITY NAME', 'SCORE','SERVICE CODE',\n",
    "       'SERVICE DESCRIPTION', 'EMPLOYEE ID', 'FACILITY ADDRESS',\n",
    "       'FACILITY CITY','FACILITY ID', 'FACILITY STATE', 'FACILITY ZIP', 'OWNER ID', 'OWNER NAME', \n",
    "        'PE DESCRIPTION',  'PROGRAM ELEMENT (PE)', 'PROGRAM NAME', 'PROGRAM STATUS', 'RECORD ID' \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2018, 4, 25, 0, 0),\n",
       "  'PNR',\n",
       "  42.88638687133789,\n",
       "  45.42646026611328,\n",
       "  45.5674934387207,\n",
       "  44.613834381103516,\n",
       "  45.070518493652344,\n",
       "  1470090,\n",
       "  7449,\n",
       "  1),\n",
       " (datetime.datetime(2018, 4, 25, 0, 0),\n",
       "  'PNW',\n",
       "  69.47084045410156,\n",
       "  79.91999816894531,\n",
       "  80.11000061035156,\n",
       "  78.94000244140625,\n",
       "  79.30999755859375,\n",
       "  1088200,\n",
       "  7451,\n",
       "  1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT * FROM saffron.daily_price GROUP BY  \")\n",
    "cur.fetchmany(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete duplicaties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"delete from saffron.security a \n",
    "    using saffron.security b\n",
    "    where a.id<b.id\n",
    "    and a.ticker = b.ticker\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A',\n",
       " datetime.datetime(2017, 1, 3, 0, 0),\n",
       " datetime.datetime(2022, 2, 23, 0, 0))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the earliest availability of stocks in the database\n",
    "\n",
    "cur.execute(\"\"\"select t1.ticker  , min(t1.date), max(t1.date)\n",
    "from saffron.daily_price t1\n",
    "group by t1.ticker\"\"\")\n",
    "cur.fetchone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur.execute(\"\"\"select ticker, count(ticker) from saffron.security\n",
    "group by ticker\n",
    "having count(ticker)>1\n",
    "order by ticker\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
