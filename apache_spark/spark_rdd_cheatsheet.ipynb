{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# introduction\n",
    "\n",
    "\n",
    "In this Jupyter Notebook you will find materials about \n",
    "1. <span style=\"color:red\">RDD</span>   \n",
    "- Reading a text file (from local or HDFS)\n",
    "- map() and flatMap\n",
    "- reduceByKey(), groupByKey(), sortByKey(), keys(), and values()\n",
    "- join(), rightOuterJoin(), leftOuterJoin(), cogroup(), subtractByKey()\n",
    "- with key/value data, use mapValues() and flatMapValues() of your transformation doesn't affect the keys. It is more efficient because it allows spark to maintain the same partitioning as original RDD instead of shuffling data.\n",
    "- filter()\n",
    "* Question: am I modifying the keys: yes then use map and flatMap, no then use mapValues and flatMapValues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"HADOOP_HOME\"] = \"C:\\\\hadoop\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some hints\n",
    "\n",
    "max for each item: reduceByKey(lambda x,y : max(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where driver is in spark-master container. check the README.me file\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"spppppppp\")\n",
    "    .master(\"spark://spark-master:7077\") # Spark stand alone\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# if driver is running in local.\n",
    "# spark = (\n",
    "#     SparkSession.builder.appName(\"spppppppp\")\n",
    "#     .master(\"spark://localhost:7077\") # Spark stand alone\n",
    "#     # .master(\"local[*]\") # if runnung local\n",
    "#     # .master(\"yarn\")\n",
    "#     # .master(\"mesos://<mesos-master-url>\")\n",
    "#     # .config(\"spark.jars\", \"c:/java/postgresql-42.7.5.jar\")    \n",
    "#     # .config(\"spark.driver.extraClassPath\", \"c:/java/postgresql-42.7.5.jar\")\n",
    "#     # .config(\"spark.executor.extraClassPath\", \"c:/java/postgresql-42.7.5.jar\")\n",
    "#     # .config(\"spark.driver.host\", \"10.0.0.177\") \n",
    "#     # .config(\"spark.executor.memory\", \"2g\")\n",
    "#     # .config(\"spark.driver.memory\", \"2g\")\n",
    "#     .getOrCreate()\n",
    "# )\n",
    "sc =spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['172.19.0.5:36089', '172.19.0.4:33291', 'b797753f41f5:46101']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get executor memory status\n",
    "executor_status = sc._jsc.sc().getExecutorMemoryStatus()\n",
    "\n",
    "# Convert Java Map to a Python dictionary\n",
    "executor_status_dict = sc._gateway.jvm.scala.collection.JavaConversions.mapAsJavaMap(executor_status)\n",
    "\n",
    "# Get the keys (nodes)\n",
    "nodes = list(executor_status_dict.keys())\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_tracker = sc.statusTracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from the share docker volume when driver is in spark-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+--------+-----+----------+\n",
      "|order_id|product_id|user_id|quantity|price| timestamp|\n",
      "+--------+----------+-------+--------+-----+----------+\n",
      "|       0|       553|   4397|       8|490.6|2023-08-18|\n",
      "|       1|       441|   6066|       2|23.87|2023-10-09|\n",
      "+--------+----------+-------+--------+-----+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales = spark.read.option(\"header\", \"true\").csv(\"/data/practice/sales.csv\")\n",
    "sales.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+--------+-----+----------+-----+\n",
      "|order_id|product_id|user_id|quantity|price| timestamp|   a0|\n",
      "+--------+----------+-------+--------+-----+----------+-----+\n",
      "|       0|       553|   4397|       8|490.6|2023-08-18|981.2|\n",
      "|       1|       441|   6066|       2|23.87|2023-10-09|47.74|\n",
      "+--------+----------+-------+--------+-----+----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.withColumn(\"a0\", col(\"price\")*2).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.select(\"user_id\").distinct().count(), sales.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'app-20250317050259-0002'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your Spark driver's REST API URL\n",
    "spark_driver_url = \"http://localhost:4040/api/v1/applications\"\n",
    "\n",
    "# Get the list of applications\n",
    "response = requests.get(spark_driver_url)\n",
    "applications = response.json()\n",
    "\n",
    "# Get the application ID of the first application\n",
    "applications[0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'driver',\n",
       "  'hostPort': 'b797753f41f5:46101',\n",
       "  'isActive': True,\n",
       "  'rddBlocks': 0,\n",
       "  'memoryUsed': 857851,\n",
       "  'diskUsed': 0,\n",
       "  'totalCores': 0,\n",
       "  'maxTasks': 0,\n",
       "  'activeTasks': 0,\n",
       "  'failedTasks': 0,\n",
       "  'completedTasks': 0,\n",
       "  'totalTasks': 0,\n",
       "  'totalDuration': 548629,\n",
       "  'totalGCTime': 112,\n",
       "  'totalInputBytes': 0,\n",
       "  'totalShuffleRead': 0,\n",
       "  'totalShuffleWrite': 0,\n",
       "  'isBlacklisted': False,\n",
       "  'maxMemory': 455501414,\n",
       "  'addTime': '2025-03-17T05:02:59.014GMT',\n",
       "  'executorLogs': {},\n",
       "  'memoryMetrics': {'usedOnHeapStorageMemory': 857851,\n",
       "   'usedOffHeapStorageMemory': 0,\n",
       "   'totalOnHeapStorageMemory': 455501414,\n",
       "   'totalOffHeapStorageMemory': 0},\n",
       "  'blacklistedInStages': [],\n",
       "  'peakMemoryMetrics': {'JVMHeapMemory': 204195840,\n",
       "   'JVMOffHeapMemory': 174712608,\n",
       "   'OnHeapExecutionMemory': 0,\n",
       "   'OffHeapExecutionMemory': 0,\n",
       "   'OnHeapStorageMemory': 1135791,\n",
       "   'OffHeapStorageMemory': 0,\n",
       "   'OnHeapUnifiedMemory': 1135791,\n",
       "   'OffHeapUnifiedMemory': 0,\n",
       "   'DirectPoolMemory': 33711040,\n",
       "   'MappedPoolMemory': 0,\n",
       "   'ProcessTreeJVMVMemory': 0,\n",
       "   'ProcessTreeJVMRSSMemory': 0,\n",
       "   'ProcessTreePythonVMemory': 0,\n",
       "   'ProcessTreePythonRSSMemory': 0,\n",
       "   'ProcessTreeOtherVMemory': 0,\n",
       "   'ProcessTreeOtherRSSMemory': 0,\n",
       "   'MinorGCCount': 19,\n",
       "   'MinorGCTime': 112,\n",
       "   'MajorGCCount': 0,\n",
       "   'MajorGCTime': 0,\n",
       "   'TotalGCTime': 112},\n",
       "  'attributes': {},\n",
       "  'resources': {},\n",
       "  'resourceProfileId': 0,\n",
       "  'isExcluded': False,\n",
       "  'excludedInStages': []},\n",
       " {'id': '1',\n",
       "  'hostPort': '172.19.0.5:36089',\n",
       "  'isActive': True,\n",
       "  'rddBlocks': 0,\n",
       "  'memoryUsed': 331410,\n",
       "  'diskUsed': 0,\n",
       "  'totalCores': 2,\n",
       "  'maxTasks': 2,\n",
       "  'activeTasks': 0,\n",
       "  'failedTasks': 0,\n",
       "  'completedTasks': 6,\n",
       "  'totalTasks': 6,\n",
       "  'totalDuration': 1699,\n",
       "  'totalGCTime': 24,\n",
       "  'totalInputBytes': 7046172,\n",
       "  'totalShuffleRead': 88243,\n",
       "  'totalShuffleWrite': 88243,\n",
       "  'isBlacklisted': False,\n",
       "  'maxMemory': 455501414,\n",
       "  'addTime': '2025-03-17T05:03:00.521GMT',\n",
       "  'executorLogs': {'stdout': 'http://localhost:8081/logPage/?appId=app-20250317050259-0002&executorId=1&logType=stdout',\n",
       "   'stderr': 'http://localhost:8081/logPage/?appId=app-20250317050259-0002&executorId=1&logType=stderr'},\n",
       "  'memoryMetrics': {'usedOnHeapStorageMemory': 331410,\n",
       "   'usedOffHeapStorageMemory': 0,\n",
       "   'totalOnHeapStorageMemory': 455501414,\n",
       "   'totalOffHeapStorageMemory': 0},\n",
       "  'blacklistedInStages': [],\n",
       "  'peakMemoryMetrics': {'JVMHeapMemory': 243052752,\n",
       "   'JVMOffHeapMemory': 80013624,\n",
       "   'OnHeapExecutionMemory': 0,\n",
       "   'OffHeapExecutionMemory': 0,\n",
       "   'OnHeapStorageMemory': 1402120,\n",
       "   'OffHeapStorageMemory': 0,\n",
       "   'OnHeapUnifiedMemory': 1402120,\n",
       "   'OffHeapUnifiedMemory': 0,\n",
       "   'DirectPoolMemory': 17841480,\n",
       "   'MappedPoolMemory': 0,\n",
       "   'ProcessTreeJVMVMemory': 0,\n",
       "   'ProcessTreeJVMRSSMemory': 0,\n",
       "   'ProcessTreePythonVMemory': 0,\n",
       "   'ProcessTreePythonRSSMemory': 0,\n",
       "   'ProcessTreeOtherVMemory': 0,\n",
       "   'ProcessTreeOtherRSSMemory': 0,\n",
       "   'MinorGCCount': 8,\n",
       "   'MinorGCTime': 43,\n",
       "   'MajorGCCount': 0,\n",
       "   'MajorGCTime': 0,\n",
       "   'TotalGCTime': 43},\n",
       "  'attributes': {},\n",
       "  'resources': {},\n",
       "  'resourceProfileId': 0,\n",
       "  'isExcluded': False,\n",
       "  'excludedInStages': []},\n",
       " {'id': '0',\n",
       "  'hostPort': '172.19.0.4:33291',\n",
       "  'isActive': True,\n",
       "  'rddBlocks': 0,\n",
       "  'memoryUsed': 456037,\n",
       "  'diskUsed': 0,\n",
       "  'totalCores': 2,\n",
       "  'maxTasks': 2,\n",
       "  'activeTasks': 0,\n",
       "  'failedTasks': 0,\n",
       "  'completedTasks': 9,\n",
       "  'totalTasks': 9,\n",
       "  'totalDuration': 1746,\n",
       "  'totalGCTime': 27,\n",
       "  'totalInputBytes': 10438186,\n",
       "  'totalShuffleRead': 176545,\n",
       "  'totalShuffleWrite': 176545,\n",
       "  'isBlacklisted': False,\n",
       "  'maxMemory': 455501414,\n",
       "  'addTime': '2025-03-17T05:03:00.515GMT',\n",
       "  'executorLogs': {'stdout': 'http://localhost:8082/logPage/?appId=app-20250317050259-0002&executorId=0&logType=stdout',\n",
       "   'stderr': 'http://localhost:8082/logPage/?appId=app-20250317050259-0002&executorId=0&logType=stderr'},\n",
       "  'memoryMetrics': {'usedOnHeapStorageMemory': 456037,\n",
       "   'usedOffHeapStorageMemory': 0,\n",
       "   'totalOnHeapStorageMemory': 455501414,\n",
       "   'totalOffHeapStorageMemory': 0},\n",
       "  'blacklistedInStages': [],\n",
       "  'peakMemoryMetrics': {'JVMHeapMemory': 218699424,\n",
       "   'JVMOffHeapMemory': 80785856,\n",
       "   'OnHeapExecutionMemory': 0,\n",
       "   'OffHeapExecutionMemory': 0,\n",
       "   'OnHeapStorageMemory': 1422774,\n",
       "   'OffHeapStorageMemory': 0,\n",
       "   'OnHeapUnifiedMemory': 1422774,\n",
       "   'OffHeapUnifiedMemory': 0,\n",
       "   'DirectPoolMemory': 12598686,\n",
       "   'MappedPoolMemory': 0,\n",
       "   'ProcessTreeJVMVMemory': 0,\n",
       "   'ProcessTreeJVMRSSMemory': 0,\n",
       "   'ProcessTreePythonVMemory': 0,\n",
       "   'ProcessTreePythonRSSMemory': 0,\n",
       "   'ProcessTreeOtherVMemory': 0,\n",
       "   'ProcessTreeOtherRSSMemory': 0,\n",
       "   'MinorGCCount': 10,\n",
       "   'MinorGCTime': 54,\n",
       "   'MajorGCCount': 0,\n",
       "   'MajorGCTime': 0,\n",
       "   'TotalGCTime': 54},\n",
       "  'attributes': {},\n",
       "  'resources': {},\n",
       "  'resourceProfileId': 0,\n",
       "  'isExcluded': False,\n",
       "  'excludedInStages': []}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executors_url = f\"http://localhost:4040/api/v1/applications/{applications[0]['id']}/executors\"\n",
    "executors_response = requests.get(executors_url)\n",
    "executors_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.text(\"hdfs://hadoop-namenode:9000/data/test/Common_Sense.txt\")\n",
    "common_sense = sc.textFile(\"/data/common_sense.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Th': 54,\n",
       "             '  ': 64,\n",
       "             'mo': 15,\n",
       "             'wh': 52,\n",
       "             'of': 58,\n",
       "             'at': 10,\n",
       "             'yo': 10,\n",
       "             'be': 43,\n",
       "             '': 315,\n",
       "             'Ti': 2,\n",
       "             'Au': 1,\n",
       "             'Re': 3,\n",
       "             'La': 1,\n",
       "             'Cr': 2,\n",
       "             '**': 2,\n",
       "             'CO': 1,\n",
       "             'ad': 7,\n",
       "             'IN': 3,\n",
       "             'AM': 1,\n",
       "             'On': 3,\n",
       "             'SU': 1,\n",
       "             'A ': 3,\n",
       "             'ca': 18,\n",
       "             'Ma': 4,\n",
       "             'Or': 1,\n",
       "             'PH': 1,\n",
       "             'Pr': 8,\n",
       "             'MD': 1,\n",
       "             'Co': 10,\n",
       "             'By': 2,\n",
       "             'Pe': 5,\n",
       "             'su': 29,\n",
       "             'cu': 2,\n",
       "             're': 49,\n",
       "             'As': 11,\n",
       "             'ne': 22,\n",
       "             'in': 58,\n",
       "             'ow': 4,\n",
       "             'th': 159,\n",
       "             'co': 72,\n",
       "             'pr': 37,\n",
       "             'In': 22,\n",
       "             'ce': 3,\n",
       "             'wo': 20,\n",
       "             'se': 15,\n",
       "             'un': 33,\n",
       "             'ar': 19,\n",
       "             'de': 28,\n",
       "             'ex': 9,\n",
       "             'AU': 1,\n",
       "             'P.': 1,\n",
       "             'Vi': 1,\n",
       "             'it': 11,\n",
       "             'a ': 13,\n",
       "             'Wh': 13,\n",
       "             'Pu': 2,\n",
       "             'wi': 46,\n",
       "             'bu': 9,\n",
       "             'Ph': 2,\n",
       "             'OF': 3,\n",
       "             'WI': 2,\n",
       "             'So': 6,\n",
       "             'li': 24,\n",
       "             'di': 24,\n",
       "             'wa': 13,\n",
       "             'ha': 24,\n",
       "             'pu': 8,\n",
       "             'mi': 10,\n",
       "             'go': 23,\n",
       "             'pa': 17,\n",
       "             'an': 65,\n",
       "             'ot': 15,\n",
       "             'to': 35,\n",
       "             'pe': 19,\n",
       "             'he': 12,\n",
       "             'hi': 11,\n",
       "             'no': 24,\n",
       "             'fo': 22,\n",
       "             'br': 3,\n",
       "             'by': 12,\n",
       "             'Bu': 19,\n",
       "             'oc': 2,\n",
       "             'ap': 5,\n",
       "             'bo': 2,\n",
       "             'ma': 28,\n",
       "             'el': 10,\n",
       "             'ag': 11,\n",
       "             'fi': 7,\n",
       "             '(n': 1,\n",
       "             'He': 5,\n",
       "             'ea': 6,\n",
       "             'I ': 14,\n",
       "             'gl': 3,\n",
       "             'Ab': 2,\n",
       "             'na': 13,\n",
       "             'me': 10,\n",
       "             'ye': 10,\n",
       "             'Fi': 7,\n",
       "             'Se': 14,\n",
       "             'To': 8,\n",
       "             'af': 7,\n",
       "             'ch': 12,\n",
       "             'ki': 15,\n",
       "             'em': 2,\n",
       "             'sa': 14,\n",
       "             'ni': 1,\n",
       "             'vi': 8,\n",
       "             'tr': 13,\n",
       "             'gi': 4,\n",
       "             'kn': 5,\n",
       "             'as': 9,\n",
       "             'is': 23,\n",
       "             'en': 9,\n",
       "             'so': 16,\n",
       "             'fa': 12,\n",
       "             'Tu': 1,\n",
       "             'An': 7,\n",
       "             'ob': 11,\n",
       "             'eq': 4,\n",
       "             'ac': 10,\n",
       "             'av': 1,\n",
       "             'ge': 4,\n",
       "             'ho': 7,\n",
       "             'we': 10,\n",
       "             'la': 12,\n",
       "             'aw': 2,\n",
       "             'Go': 3,\n",
       "             'do': 13,\n",
       "             'ju': 3,\n",
       "             'Cæ': 1,\n",
       "             'Ne': 1,\n",
       "             'cr': 4,\n",
       "             'Lo': 3,\n",
       "             'Mo': 3,\n",
       "             'ov': 2,\n",
       "             'ab': 5,\n",
       "             'i.': 2,\n",
       "             'op': 7,\n",
       "             'ya': 1,\n",
       "             'ba': 1,\n",
       "             'si': 6,\n",
       "             'po': 18,\n",
       "             'on': 9,\n",
       "             'ri': 2,\n",
       "             'ta': 3,\n",
       "             'am': 4,\n",
       "             'id': 1,\n",
       "             'pl': 6,\n",
       "             'fe': 6,\n",
       "             'ti': 5,\n",
       "             '(f': 1,\n",
       "             'En': 6,\n",
       "             'gr': 6,\n",
       "             've': 4,\n",
       "             'mu': 5,\n",
       "             'Ye': 3,\n",
       "             'es': 2,\n",
       "             'lo': 2,\n",
       "             'al': 12,\n",
       "             'Wi': 1,\n",
       "             'st': 12,\n",
       "             'Tw': 1,\n",
       "             'If': 2,\n",
       "             'fr': 12,\n",
       "             'ro': 3,\n",
       "             'ou': 13,\n",
       "             'ev': 9,\n",
       "             'TH': 2,\n",
       "             'Vo': 2,\n",
       "             'It': 10,\n",
       "             'te': 12,\n",
       "             'Br': 10,\n",
       "             'ef': 5,\n",
       "             'if': 2,\n",
       "             'up': 3,\n",
       "             'Am': 8,\n",
       "             'Al': 3,\n",
       "             'Gr': 1,\n",
       "             'tu': 1,\n",
       "             'Eu': 4,\n",
       "             'dr': 2,\n",
       "             'sh': 8,\n",
       "             'qu': 4,\n",
       "             'or': 10,\n",
       "             'No': 4,\n",
       "             'du': 1,\n",
       "             'Mu': 1,\n",
       "             'Be': 2,\n",
       "             'va': 1,\n",
       "             'pi': 2,\n",
       "             'Me': 1,\n",
       "             'Ev': 1,\n",
       "             'us': 4,\n",
       "             'Sm': 1,\n",
       "             'bl': 2,\n",
       "             'da': 4,\n",
       "             'sl': 1,\n",
       "             'ig': 2,\n",
       "             'tw': 1,\n",
       "             'sc': 2,\n",
       "             'my': 1,\n",
       "             'le': 4,\n",
       "             'ru': 2,\n",
       "             'Le': 2,\n",
       "             'im': 4,\n",
       "             'Sh': 5,\n",
       "             'Dr': 2,\n",
       "             '¹ ': 2,\n",
       "             'O ': 2,\n",
       "             'Af': 1,\n",
       "             'fu': 2,\n",
       "             'We': 3,\n",
       "             'Ou': 2,\n",
       "             'De': 2,\n",
       "             'hu': 1,\n",
       "             'Fo': 3,\n",
       "             ' 1': 2,\n",
       "             ' 4': 3,\n",
       "             ' 3': 1,\n",
       "             ' 5': 1,\n",
       "             ' 8': 1,\n",
       "             'Te': 1,\n",
       "             'ci': 3,\n",
       "             'ke': 1,\n",
       "             'gu': 2,\n",
       "             'Ca': 2,\n",
       "             'sp': 1,\n",
       "             'Yo': 2,\n",
       "             'Su': 1,\n",
       "             'Ch': 2,\n",
       "             'nu': 5,\n",
       "             'Im': 1,\n",
       "             '(o': 2,\n",
       "             'Un': 2,\n",
       "             'AP': 1,\n",
       "             'Si': 2,\n",
       "             'ra': 2,\n",
       "             'bi': 2,\n",
       "             'Ce': 1,\n",
       "             'Ho': 1,\n",
       "             'sw': 1,\n",
       "             '-b': 1,\n",
       "             'Qu': 2,\n",
       "             'Bi': 1,\n",
       "             'Ja': 1,\n",
       "             '¹\"': 1,\n",
       "             '--': 1,\n",
       "             '(w': 2,\n",
       "             '\"I': 3,\n",
       "             '-I': 1,\n",
       "             'au': 1,\n",
       "             'F ': 1,\n",
       "             '\"N': 1,\n",
       "             '\"A': 1,\n",
       "             'Ni': 1,\n",
       "             'Jo': 1,\n",
       "             '\"H': 1,\n",
       "             'Ge': 1,\n",
       "             'Tr': 1,\n",
       "             'Hu': 1,\n",
       "             'Gu': 14,\n",
       "             'Up': 1,\n",
       "             'St': 3,\n",
       "             'ST': 1,\n",
       "             'PL': 1,\n",
       "             'ww': 1,\n",
       "             '1.': 21,\n",
       "             '(t': 1,\n",
       "             'cl': 1,\n",
       "             'ph': 1,\n",
       "             'ei': 1,\n",
       "             'Li': 2,\n",
       "             'Va': 1,\n",
       "             'LI': 3,\n",
       "             'PR': 1,\n",
       "             'TR': 1,\n",
       "             'DA': 1,\n",
       "             'wr': 1,\n",
       "             'OT': 1,\n",
       "             'Ar': 3,\n",
       "             '50': 1,\n",
       "             'U.': 1,\n",
       "             'Sa': 1,\n",
       "             '($': 1,\n",
       "             'DO': 1,\n",
       "             'Pl': 1,\n",
       "             'vo': 1,\n",
       "             'ed': 2})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sense.map(lambda x:x[:2]).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = d[\"ratings\"].map(lambda x:x[2]).countByValue()\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of stopwords to be removed from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mamma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark://10.0.0.177:51545/files/Common_Sense.txt',\n",
       " 'spark://10.0.0.177:51545/files/IMDBDataset.csv',\n",
       " 'spark://10.0.0.177:51545/files/OntheOriginofSpecies.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addFiles just works with absolute paths\n",
    "import os\n",
    "# \"file:///\" + os.path.abspath(\"data/Common_Sense.txt\").replace(\"\\\\\",'/')\n",
    "sc.addFile('file:///c:/Users/mamma/my_git/data-science-old/apache_spark/data/Common_Sense.txt')\n",
    "sc.addFile('file:///c:/Users/mamma/my_git/data-science-old/apache_spark/data/OntheOriginofSpecies.txt')\n",
    "sc.addFile(\"file:///c:/Users/mamma/my_git/data-science-old/apache_spark/data/IMDBDataset.csv\")\n",
    "sc.listFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mamma\\\\AppData\\\\Local\\\\Temp\\\\spark-b75a711a-e447-4739-b810-826a312fb267\\\\userFiles-077d407d-2529-4444-ac37-88a547fe5a0e\\\\Common_Sense.txt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# didn't work when driver in local\n",
    "file_path = SparkFiles.get(\"Common_Sense.txt\")\n",
    "sc.textFile(file_path).take(2)\n",
    "file_pathdf = spark.read.text(\"hdfs:///opt/bitnami/spark/data/Common_Sense.txt\")\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '1193', '5', '978300760'], ['1', '661', '3', '978302109']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "\n",
    "for k in [\"movies\",\"ratings\",\"users\"]:\n",
    "    d[k] = sc.textFile(f\"/data/ml-1m/{k}.dat\").map(lambda li:li.split(\"::\"))\n",
    "d[\"ratings\"].take(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '1193', '5', '978300760'], ['1', '661', '3', '978302109']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"ratings\"].take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'5': 226310, '3': 261197, '4': 348971, '2': 107557, '1': 56174})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = d[\"ratings\"].map(lambda x:x[2]).countByValue()\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5', 1), ('3', 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('5', 226310), ('4', 348971), ('3', 261197), ('2', 107557), ('1', 56174)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating2 = d[\"ratings\"].map(lambda x: (x[2], 1))\n",
    "rating2syn = rating2.reduceByKey(lambda x, y: x+y)\n",
    "rating2syn.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('5', '1193'), ('3', '661')]\n",
      "[('5', ('1193', 1)), ('3', ('661', 1))]\n"
     ]
    }
   ],
   "source": [
    "ratingKV = d[\"ratings\"].map(lambda x:(x[2],x[1]))\n",
    "print(ratingKV.take(2))\n",
    "print( ratingKV.mapValues(lambda x: (x,1)).take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('5', (391123353, 226310)),\n",
       " ('3', (501107422, 261197)),\n",
       " ('4', (654499954, 348971)),\n",
       " ('2', (208381312, 107557)),\n",
       " ('1', (110817755, 56174))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating3 = ratingKV.mapValues(lambda x: (x,1)).reduceByKey(lambda x,y:(int(x[0])+int(y[0]),int(x[1])+int(y[1])))\n",
    "rating3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('5', 1728.2636781406036), ('3', 1918.5037423860151), ('4', 1875.5138793767962), ('2', 1937.4035348698828), ('1', 1972.758838608609)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('5', (391123353, 226310)),\n",
       " ('3', (501107422, 261197)),\n",
       " ('4', (654499954, 348971)),\n",
       " ('2', (208381312, 107557)),\n",
       " ('1', (110817755, 56174))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "averagePerRating = rating3.mapValues(lambda x:x[0]/x[1])\n",
    "print(averagePerRating.collect())\n",
    "rating3.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from HDFS\n",
    "\n",
    " On the Origin of Species, by Charles Darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "rdd1 = sc.textFile(\n",
    "    \"hdfs:///user/hadoop/OntheOriginofSpecies.txt\").flatMap(lambda text: re.compile(r'\\W',re.UNICODE).split(text.lower()))\n",
    "rdd1 = rdd1.filter(lambda x: x not in stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proj ['project', 'project', 'project']\n",
      "gute ['gutenberg', 'gutenberg', 'gutenberg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd2 = rdd1.groupBy(lambda x:x[:4])\n",
    "for k , v in rdd2.take(2):\n",
    "    print(k,list(v)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'title'), (1, '1st')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def swapTuple(t):\n",
    "    return (t[1],t[0])\n",
    "numOccurance = rdd1.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).map(swapTuple).sortByKey()\n",
    "numOccurance.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proj ['project', 'projecting']\n",
      "gute ['gutenberg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd3 = rdd1.distinct()\n",
    "rdd4 = rdd3.groupBy(lambda x:x[:4])\n",
    "for k , v in rdd4.take(2):\n",
    "    print(k,list(v)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"regression\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "server_file = \"hdfs:///192.168.0.233:9000\"\n",
    "file_uri = \"hdfs:///user/hadoop/OntheOriginofSpecies.txt\"\n",
    "# text = sc.textFile(\"hdfs:///testdata/stockdata2.csv\")\n",
    "\n",
    "URI           = sc._gateway.jvm.java.net.URI\n",
    "Path          = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "FileSystem    = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "Configuration = sc._gateway.jvm.org.apache.hadoop.conf.Configuration\n",
    "\n",
    "log4jLogger = sc._jvm.org.apache.log4j\n",
    "LOGGER = log4jLogger.LogManager.getLogger(__name__)\n",
    "LOGGER.info(\"pyspark script logger initialized\")\n",
    "\n",
    "fs = FileSystem.get(URI(server_file), Configuration())\n",
    "status = fs.listStatus(Path('movies/'))\n",
    "\n",
    "df = spark.read.csv(\"hdfs:///user/hadoop/OntheOriginofSpecies.txt\")\n",
    "print('\\033[92m')\n",
    "print(\"test is done ***************************************\")\n",
    "for fileStatus in status:\n",
    "    print(fileStatus.getPath())\n",
    "# print(text.take(2))\n",
    "\n",
    "print('\\033[0m')\n",
    "\n",
    "\n",
    "\n",
    "cmd = 'hdfs dfs -ls movies/'\n",
    "files = subprocess.check_output(cmd, shell=True).strip().split('\\n')\n",
    "for pat in files:\n",
    "  print (pat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
