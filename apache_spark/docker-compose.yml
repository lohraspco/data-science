version: "3.8"

services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    networks:
      - hadoop-network

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    ports:
      - "55070:50070" # HDFS Web UI
      - "9000:9000"   # HDFS NameNode RPC
    environment:
      - CLUSTER_NAME=mycluster
      - CLUSTER_NAME=mycluster
      - HADOOP_HOME=/opt/hadoop
      - hadoop.home.dir=/opt/hadoop
    volumes:
      - namenode_data:/hadoop/dfs/name
    networks:
      - hadoop-network
    depends_on:
      - zookeeper

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    ports:
      - "55075:50075" # Datanode web ui
      - "50010:50010"
    environment:
      - CLUSTER_NAME=mycluster
      - HADOOP_HOME=/opt/hadoop
      - hadoop.home.dir=/opt/hadoop
    volumes:
      - datanode_data:/hadoop/dfs/data
    networks:
      - hadoop-network
    depends_on:
      - namenode

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    hostname: resourcemanager
    container_name: resourcemanager
    ports:
      - "8288:8088"  # ResourceManager Web UI
    environment:
      - CLUSTER_NAME=mycluster
      - YARN_RESOURCEMANAGER_HOSTNAME=resourcemanager
    networks:
      - hadoop-network
    depends_on:
      - namenode
      - datanode

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    hostname: nodemanager
    container_name: nodemanager
    environment:
      - CLUSTER_NAME=mycluster
      - YARN_RESOURCEMANAGER_HOSTNAME=resourcemanager
    networks:
      - hadoop-network
    depends_on:
      - resourcemanager
      - datanode

  spark-master:
    image: bitnami/spark:latest
    ports:
      - "7180:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master port
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - spark_data:/opt/bitnami/spark/work
    networks:
      - hadoop-network
    depends_on:
      - resourcemanager  # Spark submits jobs to YARN

  spark-worker:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - spark_data:/opt/bitnami/spark/work
    networks:
      - hadoop-network
    depends_on:
      - spark-master
      - nodemanager  # Spark needs YARN NodeManagers to execute tasks

volumes:
  namenode_data:
  datanode_data:
  spark_data:

networks:
  hadoop-network:
    driver: bridge