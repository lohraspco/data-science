{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "%pip install --upgrade azure-ai-anomalydetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from azure.ai.anomalydetector import AnomalyDetectorClient\n",
    "from azure.ai.anomalydetector.models import DetectionRequest\n",
    "from azure.core.exceptions import HttpResponseError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for Azure Anomaly Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is obtained from https://archive.ics.uci.edu/ml/datasets/SML2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-03-13 02:28:49,116 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"AzureData\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= spark.read.csv(\"file:////home/hadoop/lohrasp/data-science/Azure/SML2010.csv\",\n",
    "    inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns Date and Time will be concatenated to construct the  timestamp column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      Date| Time|\n",
      "+----------+-----+\n",
      "|13/03/2012|11:45|\n",
      "|13/03/2012|12:00|\n",
      "+----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Date\",\"Time\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,concat,lit,to_timestamp,udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each time series should be a CSV file with two (and only two) columns, \"timestamp\" and \"timestamp\" (all in lowercase) as the header row.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the following code provides timestamp, but for Azure timestamp should have 'iso-8601' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not iso-8601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.withColumn(\"timestamp1\", concat(col(\"Date\"),lit(\" \") ,col(\"Time\")))\n",
    "df2 = df1.withColumn(\"timestamp\",to_timestamp(\"timestamp1\",\"dd/MM/yyyy HH:mm\"))\n",
    "for c in df.drop(\"Date\",\"time\").columns:\n",
    "    df2.withColumnRenamed(c,\"value\").select(\"timestamp\",\"value\").toPandas().to_csv(f\"data/{c}.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iso-8601\n",
    "The following ISO 8601 UTC formats are currently accepted by Azure Storage. The date value is required, while the time value is optional:([reference](\"https://docs.microsoft.com/en-us/rest/api/storageservices/formatting-datetime-values\"))\n",
    "\n",
    "    YYYY-MM-DD\n",
    "    YYYY-MM-DDThh:mm<TZDSuffix>\n",
    "    YYYY-MM-DDThh:mm:ss<TZDSuffix>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(datestring):\n",
    "    d,m,y = datestring.split(\"/\")\n",
    "    return \"-\".join([y,m,d])\n",
    "convert_date_UDF = udf(lambda z: convert_date(z),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.withColumn(\"Date1\",convert_date_UDF(\"Date\"))#\n",
    "df2 = df1.withColumn(\"timestamp\", concat(col(\"Date1\"),lit(\"T\") ,col(\"Time\")))\n",
    "df2.select(\"timestamp\").toPandas().head(2)\n",
    "for c in df.drop(\"Date\",\"time\").columns:\n",
    "    df2.withColumnRenamed(c,\"value\").select(\"timestamp\",\"value\").toPandas().to_csv(f\"data/{c}.csv\",sep=\",\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>avg(Meteo_Exterior_Sol_Oest)</th>\n",
       "      <th>avg(Temperature_Comedor_Sensor)</th>\n",
       "      <th>avg(Humedad_Comedor_Sensor)</th>\n",
       "      <th>avg(Exterior_Entalpic_1)</th>\n",
       "      <th>avg(CO2_Comedor_Sensor)</th>\n",
       "      <th>avg(Temperature_Exterior_Sensor)</th>\n",
       "      <th>avg(Humedad_Exterior_Sensor)</th>\n",
       "      <th>avg(Exterior_Entalpic_2)</th>\n",
       "      <th>avg(Weather_Temperature)</th>\n",
       "      <th>...</th>\n",
       "      <th>avg(Meteo_Exterior_Piranometro)</th>\n",
       "      <th>avg(Lighting_Habitacion_Sensor)</th>\n",
       "      <th>avg(Meteo_Exterior_Sol_Sud)</th>\n",
       "      <th>avg(Temperature_Habitacion_Sensor)</th>\n",
       "      <th>avg(Meteo_Exterior_Viento)</th>\n",
       "      <th>avg(CO2_Habitacion_Sensor)</th>\n",
       "      <th>avg(Meteo_Exterior_Sol_Est)</th>\n",
       "      <th>avg(Meteo_Exterior_Crepusculo)</th>\n",
       "      <th>avg(Exterior_Entalpic_turbo)</th>\n",
       "      <th>avg(Precipitacion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17/03/2012</td>\n",
       "      <td>17330.414958</td>\n",
       "      <td>19.400440</td>\n",
       "      <td>44.252475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.698104</td>\n",
       "      <td>17.661935</td>\n",
       "      <td>53.903472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>229.015708</td>\n",
       "      <td>44.591629</td>\n",
       "      <td>28945.614896</td>\n",
       "      <td>18.983603</td>\n",
       "      <td>1.275833</td>\n",
       "      <td>208.025354</td>\n",
       "      <td>14084.089563</td>\n",
       "      <td>321.087069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20/03/2012</td>\n",
       "      <td>906.229396</td>\n",
       "      <td>14.328148</td>\n",
       "      <td>36.612890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.390760</td>\n",
       "      <td>11.266743</td>\n",
       "      <td>71.105419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.980556</td>\n",
       "      <td>...</td>\n",
       "      <td>18.248523</td>\n",
       "      <td>17.663475</td>\n",
       "      <td>969.919646</td>\n",
       "      <td>14.127175</td>\n",
       "      <td>2.756861</td>\n",
       "      <td>201.955115</td>\n",
       "      <td>1064.447854</td>\n",
       "      <td>296.263149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  avg(Meteo_Exterior_Sol_Oest)  avg(Temperature_Comedor_Sensor)  \\\n",
       "0  17/03/2012                  17330.414958                        19.400440   \n",
       "1  20/03/2012                    906.229396                        14.328148   \n",
       "\n",
       "   avg(Humedad_Comedor_Sensor)  avg(Exterior_Entalpic_1)  \\\n",
       "0                    44.252475                       0.0   \n",
       "1                    36.612890                       0.0   \n",
       "\n",
       "   avg(CO2_Comedor_Sensor)  avg(Temperature_Exterior_Sensor)  \\\n",
       "0               205.698104                         17.661935   \n",
       "1               200.390760                         11.266743   \n",
       "\n",
       "   avg(Humedad_Exterior_Sensor)  avg(Exterior_Entalpic_2)  \\\n",
       "0                     53.903472                       0.0   \n",
       "1                     71.105419                       0.0   \n",
       "\n",
       "   avg(Weather_Temperature)  ...  avg(Meteo_Exterior_Piranometro)  \\\n",
       "0                 15.000000  ...                       229.015708   \n",
       "1                 11.980556  ...                        18.248523   \n",
       "\n",
       "   avg(Lighting_Habitacion_Sensor)  avg(Meteo_Exterior_Sol_Sud)  \\\n",
       "0                        44.591629                 28945.614896   \n",
       "1                        17.663475                   969.919646   \n",
       "\n",
       "   avg(Temperature_Habitacion_Sensor)  avg(Meteo_Exterior_Viento)  \\\n",
       "0                           18.983603                    1.275833   \n",
       "1                           14.127175                    2.756861   \n",
       "\n",
       "   avg(CO2_Habitacion_Sensor)  avg(Meteo_Exterior_Sol_Est)  \\\n",
       "0                  208.025354                 14084.089563   \n",
       "1                  201.955115                  1064.447854   \n",
       "\n",
       "   avg(Meteo_Exterior_Crepusculo)  avg(Exterior_Entalpic_turbo)  \\\n",
       "0                      321.087069                           0.0   \n",
       "1                      296.263149                           0.0   \n",
       "\n",
       "   avg(Precipitacion)  \n",
       "0            0.000000  \n",
       "1            0.926389  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df.withColumn(\"timestamp\" , convert_date_UDF(col(\"Date\"))) \n",
    "df1 = df11.groupBy(\"timestamp\").agg({c:'avg' for c in df.drop(\"Date\",\"Time\",\"timestamp\").columns})\n",
    "for c in df1.drop(\"timestamp\").columns:\n",
    "    df1.withColumnRenamed(c,\"value\").select(\"timestamp\",\"value\").toPandas().to_csv(f\"data2/{c}.csv\",sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>avg(Meteo_Exterior_Sol_Oest)</th>\n",
       "      <th>avg(Temperature_Comedor_Sensor)</th>\n",
       "      <th>avg(Humedad_Comedor_Sensor)</th>\n",
       "      <th>avg(Exterior_Entalpic_1)</th>\n",
       "      <th>avg(CO2_Comedor_Sensor)</th>\n",
       "      <th>avg(Temperature_Exterior_Sensor)</th>\n",
       "      <th>avg(Humedad_Exterior_Sensor)</th>\n",
       "      <th>avg(Exterior_Entalpic_2)</th>\n",
       "      <th>avg(Weather_Temperature)</th>\n",
       "      <th>...</th>\n",
       "      <th>avg(Meteo_Exterior_Piranometro)</th>\n",
       "      <th>avg(Lighting_Habitacion_Sensor)</th>\n",
       "      <th>avg(Meteo_Exterior_Sol_Sud)</th>\n",
       "      <th>avg(Temperature_Habitacion_Sensor)</th>\n",
       "      <th>avg(Meteo_Exterior_Viento)</th>\n",
       "      <th>avg(CO2_Habitacion_Sensor)</th>\n",
       "      <th>avg(Meteo_Exterior_Sol_Est)</th>\n",
       "      <th>avg(Meteo_Exterior_Crepusculo)</th>\n",
       "      <th>avg(Exterior_Entalpic_turbo)</th>\n",
       "      <th>avg(Precipitacion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-19</td>\n",
       "      <td>16771.943229</td>\n",
       "      <td>19.478197</td>\n",
       "      <td>34.189458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.914021</td>\n",
       "      <td>15.409863</td>\n",
       "      <td>37.146470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>222.657680</td>\n",
       "      <td>40.190433</td>\n",
       "      <td>24604.482771</td>\n",
       "      <td>18.905979</td>\n",
       "      <td>1.184563</td>\n",
       "      <td>204.308469</td>\n",
       "      <td>11141.635458</td>\n",
       "      <td>317.661243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-03-22</td>\n",
       "      <td>18136.550396</td>\n",
       "      <td>15.335876</td>\n",
       "      <td>48.926484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.914031</td>\n",
       "      <td>14.012480</td>\n",
       "      <td>58.610003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.306947</td>\n",
       "      <td>...</td>\n",
       "      <td>247.061055</td>\n",
       "      <td>45.967877</td>\n",
       "      <td>28481.745604</td>\n",
       "      <td>14.944966</td>\n",
       "      <td>1.230139</td>\n",
       "      <td>219.618667</td>\n",
       "      <td>15032.296188</td>\n",
       "      <td>323.243211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  avg(Meteo_Exterior_Sol_Oest)  avg(Temperature_Comedor_Sensor)  \\\n",
       "0  2012-03-19                  16771.943229                        19.478197   \n",
       "1  2012-03-22                  18136.550396                        15.335876   \n",
       "\n",
       "   avg(Humedad_Comedor_Sensor)  avg(Exterior_Entalpic_1)  \\\n",
       "0                    34.189458                       0.0   \n",
       "1                    48.926484                       0.0   \n",
       "\n",
       "   avg(CO2_Comedor_Sensor)  avg(Temperature_Exterior_Sensor)  \\\n",
       "0               201.914021                         15.409863   \n",
       "1               212.914031                         14.012480   \n",
       "\n",
       "   avg(Humedad_Exterior_Sensor)  avg(Exterior_Entalpic_2)  \\\n",
       "0                     37.146470                       0.0   \n",
       "1                     58.610003                       0.0   \n",
       "\n",
       "   avg(Weather_Temperature)  ...  avg(Meteo_Exterior_Piranometro)  \\\n",
       "0                 15.000000  ...                       222.657680   \n",
       "1                 11.306947  ...                       247.061055   \n",
       "\n",
       "   avg(Lighting_Habitacion_Sensor)  avg(Meteo_Exterior_Sol_Sud)  \\\n",
       "0                        40.190433                 24604.482771   \n",
       "1                        45.967877                 28481.745604   \n",
       "\n",
       "   avg(Temperature_Habitacion_Sensor)  avg(Meteo_Exterior_Viento)  \\\n",
       "0                           18.905979                    1.184563   \n",
       "1                           14.944966                    1.230139   \n",
       "\n",
       "   avg(CO2_Habitacion_Sensor)  avg(Meteo_Exterior_Sol_Est)  \\\n",
       "0                  204.308469                 11141.635458   \n",
       "1                  219.618667                 15032.296188   \n",
       "\n",
       "   avg(Meteo_Exterior_Crepusculo)  avg(Exterior_Entalpic_turbo)  \\\n",
       "0                      317.661243                           0.0   \n",
       "1                      323.243211                           0.0   \n",
       "\n",
       "   avg(Precipitacion)  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the CSV files should be zipped into one zip file without any subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: data3/CO2_Comedor_Sensor.csv (deflated 62%)\n",
      "  adding: data3/Day_Of_Week.csv (deflated 78%)\n"
     ]
    }
   ],
   "source": [
    "!zip SML2010v4.zip data3/* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The zip file should be uploaded to Azure Blob storage\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detector \n",
    "\n",
    "Create an anomaly detector in Azure portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = \"8b68d766f0af469ba3fb2ca1da3a7e8e\"\n",
    "anomaly_detector_endpoint = \"https://anomalydetectormattnaj1.cognitiveservices.azure.com/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.anomalydetector import AnomalyDetectorClient\n",
    "\n",
    "ad_client = AnomalyDetectorClient(AzureKeyCredential(subscription_key), anomaly_detector_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ad_client.list_multivariate_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Blob_SAS_token = \"sp=r&st=2022-03-14T02:48:36Z&se=2022-03-21T10:48:36Z&spr=https&sv=2020-08-04&sr=b&sig=bOfgmnfnS3bBl%2BVLPum%2B6p3LlZZItBLvu0fKOeWa7%2Bw%3D\"\n",
    "Blob_SAS_URL = \"https://aifundamentalstorge234.blob.core.windows.net/sml2010/SML2010v3.zip?sp=r&st=2022-03-14T02:48:36Z&se=2022-03-21T10:48:36Z&spr=https&sv=2020-08-04&sr=b&sig=bOfgmnfnS3bBl%2BVLPum%2B6p3LlZZItBLvu0fKOeWa7%2Bw%3D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.anomalydetector.models import ModelInfo,ModelStatus\n",
    "start_time = \"2012-03-13T11:45:00\"\n",
    "end_time = \"2012-04-11T06:30:00\" \n",
    "data_feed2 = ModelInfo(start_time=start_time, end_time=end_time, source=Blob_SAS_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Datetime with no tzinfo will be considered UTC.\n",
      "Datetime with no tzinfo will be considered UTC.\n"
     ]
    }
   ],
   "source": [
    "response_header2 = ad_client.train_multivariate_model(data_feed2, cls=lambda *args: [args[i] for i in range(len(args))])[-1]\n",
    "trained_model_id = response_header2['Location'].split(\"/\")[-1]\n",
    "new_model_list = list(ad_client.list_multivariate_model(skip=0, top=10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "--------------------\n",
      "1 available models after training.\n"
     ]
    }
   ],
   "source": [
    "model_status = None\n",
    "while model_status != ModelStatus.READY and model_status != ModelStatus.FAILED:\n",
    "     model_info = ad_client.get_multivariate_model(trained_model_id).model_info\n",
    "     model_status = model_info.status\n",
    "\n",
    "if model_status == ModelStatus.READY:\n",
    "    # Model list after training\n",
    "    new_model_list = list(ad_client.list_multivariate_model(skip=0, top=10000))\n",
    "    print(\"Done.\\n--------------------\")\n",
    "    print(\"{:d} available models after training.\".format(len(new_model_list)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect anomaly in the same data source (but a different interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.anomalydetector.models import DetectionRequest,DetectionStatus\n",
    "\n",
    "try:\n",
    "    detection_req = DetectionRequest(source=Blob_SAS_URL, start_time=start_time, end_time=end_time)\n",
    "    response_header = ad_client.detect_anomaly(trained_model_id, detection_req,\n",
    "                                                    cls=lambda *args: [args[i] for i in range(len(args))])[-1]\n",
    "    result_id = response_header['Location'].split(\"/\")[-1]\n",
    "\n",
    "    # Get results \n",
    "    r = ad_client.get_detection_result(result_id)\n",
    "    while r.summary.status != DetectionStatus.READY and r.summary.status != DetectionStatus.FAILED:\n",
    "        r = ad_client.get_detection_result(result_id)\n",
    "        time.sleep(2)\n",
    "except HttpResponseError as e:\n",
    "    print('Error code: {}'.format(e.error.code), 'Error message: {}'.format(e.error.message))\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
