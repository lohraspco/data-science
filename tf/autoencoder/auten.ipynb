{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ # or tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 64, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decode_image_from_raw_data(image_path=\"images/train/500.png\"):\n",
    "    im_path = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_image(im_path)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # img = tf.image.resize(img, [500,500])\n",
    "    return img\n",
    "img = decode_image_from_raw_data()\n",
    "# plt.title(\"TensorFlow Logo with shape {}\".format(img.shape))\n",
    "_ = plt.imshow(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# datagen = image_dataset_from_directory(\"images/\")\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_batches = datagen.flow_from_directory(\"images/train/\",target_size=(64,64),batch_size=256,shuffle=True,class_mode=\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 64, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageinput = layers.Input(shape=img.shape)\n",
    "x = layers.Conv2D(48,kernel_size=(3,3),activation='relu',input_shape = img.shape)(imageinput)\n",
    "x = layers.MaxPooling2D((2,2),padding='same')(x)\n",
    "x = layers.Conv2D(96,(3,3),activation='relu',padding='same')(x)\n",
    "x = layers.MaxPooling2D((2,2),padding='same')(x)\n",
    "x = layers.Conv2D(192,(3,3),activation='relu',padding='same')(x)\n",
    "x = layers.MaxPooling2D((2,2),padding='same')(x)\n",
    "encoded = layers.Conv2D(32,(1,1),activation='relu',padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directinput = layers.Input(shape=(8,8,32))\n",
    "x = layers.Conv2D(192, (1, 1), activation='relu', padding='same')(directinput)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(96,(3,3),activation='relu',padding='same')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(192,(3,3),activation='relu',padding='same')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape = img.shape)(imageinput)\n",
    "decoded = layers.Conv2D(3,(3,3),activation='sigmoid',padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: <keras.layers.convolutional.Conv2D object at 0x7fbe2c175f40>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-114e34d9b915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageinput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectinput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mautoEncoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageinput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_graph_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# A Network does not create weights of its own, thus it is already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_validate_graph_inputs_and_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    776\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0mcls_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         raise ValueError(f'Output tensors of a {cls_name} model must be '\n\u001b[0m\u001b[1;32m    779\u001b[0m                          \u001b[0;34m'the output of a TensorFlow `Layer` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m                          f'(thus holding past layer metadata). Found: {x}')\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: <keras.layers.convolutional.Conv2D object at 0x7fbe2c175f40>"
     ]
    }
   ],
   "source": [
    "encoder = Model(imageinput,encoded)\n",
    "decoder = Model(directinput,decoded)\n",
    "autoEncoder = Model(imageinput,decoder(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(img).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-486bec4a400f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# model = keras.Model(x,decoded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "x = keras.Input(shape=img.shape)\n",
    "# x1 =layers.Flatten()(x)\n",
    "encoder = layers.Conv2D(filters=128,kernel_size=5,strides=2)(x)\n",
    "encoder = layers.MaxPool2D((2,2),padding='same')(encoder)\n",
    "encoder = layers.LeakyReLU(alpha=0.2)(encoder)\n",
    "encoder = layers.BatchNormalization(axis=1)(encoder)\n",
    "flatt = =tf.size(img).numpy()\n",
    "# encoded = layers.Dense(16,activation='softmax')(x1)\n",
    "# decoded = layers.Dense(shape=tf.size(img).numpy(),activation='sigmoid')(encoded)\n",
    "# model = keras.Model(x,decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER\n",
    "input_img = Input(shape=(64, 64, 3))  \n",
    "x = Conv2D(48, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded = Conv2D(32, (1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "# LATENT SPACE\n",
    "latentSize = (8,8,32)\n",
    "\n",
    "# DECODER\n",
    "direct_input = Input(shape=latentSize)\n",
    "x = Conv2D(192, (1, 1), activation='relu', padding='same')(direct_input)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(48, (3, 3), activation='relu', padding='same')(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# COMPILE\n",
    "encoder = Model(input_img, encoded)\n",
    "decoder = Model(direct_input, decoded)\n",
    "autoencoder = Model(input_img, decoder(encoded))\n",
    "\n",
    "autoencoder.compile(optimizer='Adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 64, 64, 48)        1344      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 32, 32, 48)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 32, 32, 96)        41568     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 16, 16, 96)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 16, 16, 192)       166080    \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 8, 8, 192)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 8, 8, 32)          6176      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,168\n",
      "Trainable params: 215,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 8, 8, 32)]        0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 8, 8, 192)         6336      \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 16, 16, 192)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 16, 16, 192)       331968    \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 32, 32, 192)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 32, 32, 96)        165984    \n",
      "                                                                 \n",
      " up_sampling2d_14 (UpSamplin  (None, 64, 64, 96)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 64, 64, 48)        41520     \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 64, 64, 3)         1299      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 547,107\n",
      "Trainable params: 547,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 256; EPOCHS = 10\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_batches = train_datagen.flow_from_directory('images/',  target_size=(64,64), shuffle=True, class_mode='input', batch_size=BATCH_SIZE)\n",
    "train_batches.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-f3cac48f93f9>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = autoencoder.fit_generator(train_batches,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 - 239s - loss: 0.6414 - 239s/epoch - 6s/step\n",
      "Epoch 2/10\n",
      "39/39 - 239s - loss: 0.6006 - 239s/epoch - 6s/step\n",
      "Epoch 3/10\n",
      "39/39 - 239s - loss: 0.5926 - 239s/epoch - 6s/step\n",
      "Epoch 4/10\n",
      "39/39 - 240s - loss: 0.5901 - 240s/epoch - 6s/step\n",
      "Epoch 5/10\n",
      "39/39 - 239s - loss: 0.5890 - 239s/epoch - 6s/step\n",
      "Epoch 6/10\n",
      "39/39 - 240s - loss: 0.5876 - 240s/epoch - 6s/step\n",
      "Epoch 7/10\n",
      "39/39 - 239s - loss: 0.5869 - 239s/epoch - 6s/step\n",
      "Epoch 8/10\n",
      "39/39 - 240s - loss: 0.5857 - 240s/epoch - 6s/step\n",
      "Epoch 9/10\n",
      "39/39 - 240s - loss: 0.5848 - 240s/epoch - 6s/step\n",
      "Epoch 10/10\n",
      "39/39 - 239s - loss: 0.5846 - 239s/epoch - 6s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = autoencoder.fit_generator(train_batches,\n",
    "        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "        epochs = EPOCHS, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import  Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-c461658417d1>:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = auto_encoder.fit_generator(input_images,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 234s - loss: 0.6115 - 234s/epoch - 746ms/step\n",
      "Epoch 2/2\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1./255)\n",
    "input_images = data_gen.flow_from_directory(\"images/\", target_size=(64,64), shuffle=True, class_mode='input')\n",
    "input_layer = Input(shape=(64,64,3))\n",
    "x = Conv2D(64,(3,3),activation='relu',padding='same')(input_layer)\n",
    "x = MaxPooling2D((2,2),padding='same')(x)\n",
    "x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n",
    "x = MaxPooling2D((2,2),padding='same')(x)\n",
    "encoded = Conv2D(32,(3,3),activation='relu',padding='same')(x)\n",
    "\n",
    "direct_input = Input(shape=(16,16,32))\n",
    "x = UpSampling2D((2,2))(direct_input)\n",
    "x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n",
    "decoded = Conv2D(3,(3,3),activation='relu',padding='same')(x)\n",
    "\n",
    "encoder = Model(input_layer,encoded)\n",
    "decoder = Model(direct_input,decoded)\n",
    "auto_encoder = Model(input_layer, decoder(encoded))\n",
    "auto_encoder.compile(optimizer='Adam', loss='binary_crossentropy')\n",
    "history = auto_encoder.fit_generator(input_images,\n",
    "        epochs = 2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(iter(train_batches))[0]\n",
    "for i in range (5):\n",
    "    plt.figure(figsize = (15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    orig = images[i,:,:,:].reshape((-1,64,64,3))\n",
    "    plt.imshow(orig)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 16, 16, 32)]      0         \n",
      "                                                                 \n",
      " up_sampling2d_10 (UpSamplin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 32, 32, 128)       36992     \n",
      "                                                                 \n",
      " up_sampling2d_11 (UpSamplin  (None, 64, 64, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 64, 64, 64)        73792     \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 64, 64, 3)         1731      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 112,515\n",
      "Trainable params: 112,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 16, 16, 32)]      0         \n",
      "                                                                 \n",
      " up_sampling2d_10 (UpSamplin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 32, 32, 128)       36992     \n",
      "                                                                 \n",
      " up_sampling2d_11 (UpSamplin  (None, 64, 64, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 64, 64, 64)        73792     \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 64, 64, 3)         1731      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 112,515\n",
      "Trainable params: 112,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
